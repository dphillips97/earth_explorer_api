{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "1. gdf can only contain 1 type of datasetName (like \"LANDSAT_8_C1\"). It's hard to get the dataset name from older datasets (like CORONA)\n",
    "2. updateOrderScene only takes a gdf as an argument; allow this to handle lists and string\n",
    "3. sceneSearch only works for points; allow to handle areas\n",
    "4. clearOrder should print a simpler message\n",
    "5. datasetSearch is basically the same as sceneSearch, but with a different action word and a different return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "#import re\n",
    "\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from ee_secret_codes import *\n",
    "\n",
    "endpoint = \"https://earthexplorer.usgs.gov/inventory/json/v/1.4.0/\"\n",
    "\n",
    "# Login parameters\n",
    "username = EE_USERNAME\n",
    "password = EE_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_request(request_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Wraps payload dictionary in correct format to pass as a request.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    request_dict: dictionary or dict-like object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    json-like object; dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return {'jsonRequest': json.dumps(request_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(action, payload=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Call EarthExplorer API using endpoint word,different for each\n",
    "    type of call.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    action: string\n",
    "        Keyword specifying endpoint, such as \"search\"\n",
    "        \n",
    "    payload: dict\n",
    "        Containing parameters required for successful API\n",
    "        call. At minimum an api key\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    return_json: python JSON-like object\n",
    "        JSON object returned from request call\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if payload:\n",
    "        params = create_request(payload)\n",
    "\n",
    "        return_json = rq.get((endpoint + action), params=params).json()\n",
    "\n",
    "    else:\n",
    "\n",
    "        return_json = rq.get((endpoint + action)).json()\n",
    "\n",
    "    return return_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(username, password):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in username and password to generate an API key,\n",
    "    required for all API calls. Does not use api_call since\n",
    "    this is a POST request. Set api_key as a global variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    username: string\n",
    "    \n",
    "    password: string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    api key: string\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Set up auths dict\n",
    "    login_payload = {'username': username,\n",
    "                     'password': password,\n",
    "                     'catalogID': \"EE\"}\n",
    "\n",
    "    login_params = create_request(login_payload)\n",
    "\n",
    "    # Post auths\n",
    "    login_response = rq.post((endpoint + \"login?\"), data=login_params).json()\n",
    "\n",
    "    # Return API key\n",
    "    return login_response['data']\n",
    "\n",
    "api_key = login(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logout():\n",
    "    \n",
    "    \"\"\"\n",
    "    Logs user out of system\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    none\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    logout_response: JSON\n",
    "        With details of successful logout\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    logout_payload = {\"apiKey\": api_key}\n",
    "                      \n",
    "    logout_response = api_call(\"logout\", logout_payload)\n",
    "    \n",
    "    return logout_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status():\n",
    "    \"\"\"\n",
    "    Checks status of current user: logged in or not logged in\n",
    "    \"\"\"\n",
    "    status_params = create_request(api_key) \n",
    "    \n",
    "    status_response = api_call(\"status\")\n",
    "    \n",
    "    return status_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearOrder():\n",
    "    \n",
    "    \"\"\"Clears item basket and returns response\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    none\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    clear_response: JSON\n",
    "        General info on basket contents\n",
    "        \n",
    "    \"\"\"\n",
    "    clear_payload = {\"apiKey\": api_key}\n",
    "\n",
    "    clear_response = api_call(\"clearorder\", clear_payload)\n",
    "\n",
    "    return clear_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemBasket():\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns contents of item basket as JSON\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    none\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    basket: JSON\n",
    "        Info on scenes added to basket\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    basket_payload = {\"apiKey\": api_key}\n",
    "    \n",
    "    basket = api_call(\"itembasket\", basket_payload)\n",
    "    \n",
    "    return basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sceneSearch(dataset_name, start_date, end_date,\n",
    "                latitude=None, longitude=None,\n",
    "                max_results=None, return_ftype='gdf'):\n",
    "    \"\"\"\n",
    "    Searches scenes from specified dataset. Only works for\n",
    "    points, not areas.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name: string\n",
    "\n",
    "    start_date: string \n",
    "        Format YYYY-MM-DD\n",
    "\n",
    "    latitude: int or float\n",
    "        In decimal degrees, WGS84\n",
    "\n",
    "    longitude: as above\n",
    "\n",
    "    max_results: int (optional)\n",
    "\n",
    "    return_gdf: boolean\n",
    "        True to return geodataframe,\n",
    "        False to return JSON\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    search_resp: geodataframe or JSON\n",
    "    \"\"\"\n",
    "\n",
    "    # Create empty dict\n",
    "    search_payload = {\"datasetName\": dataset_name,\n",
    "                      \"temporalFilter\": {\"startDate\": start_date,\n",
    "                                         \"endDate\": end_date}}\n",
    "\n",
    "    # If latitude and longitude\n",
    "    if latitude and longitude:\n",
    "        search_payload['spatialFilter'] = {\"filterType\": \"mbr\",\n",
    "                                           \"lowerLeft\": {\"latitude\": latitude,\n",
    "                                                         \"longitude\": longitude},\n",
    "                                           \"upperRight\": {\"latitude\": latitude,\n",
    "                                                          \"longitude\": longitude}}\n",
    "    if max_results:\n",
    "        search_payload['maxResults'] = max_results\n",
    "\n",
    "    # Add api key\n",
    "    search_payload['apiKey'] = api_key\n",
    "\n",
    "    # Get results as json\n",
    "    search_resp = api_call(\"search\", search_payload)\n",
    "\n",
    "    if return_ftype == 'json':\n",
    "        \n",
    "        return search_resp\n",
    "\n",
    "    else:\n",
    "\n",
    "        return get_gdf(search_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdf(search_resp_json):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts a search response JSON to a geodataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    search_resp_json: dict\n",
    "        JSON-like object returned from a GET request\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    gdf: geoDataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # normalize json to create df\n",
    "    df = json_normalize(search_resp_json['data']['results'])\n",
    "\n",
    "    # Create list to hold Polygon object from each row\n",
    "    rows_list = []\n",
    "\n",
    "    # Loop through each scene item in json\n",
    "    for scene in search_resp_json['data']['results']:\n",
    "\n",
    "        # DataFrame holds Polygons as a nested list, need to\n",
    "        # change format to [(x1, y1), (x2, y2)] for shapely\n",
    "        # Start with \"packed list\" in df\n",
    "        packed_list = scene.get('spatialFootprint').get('coordinates')[0]\n",
    "\n",
    "        # Change each item to a tuple and create a simple list\n",
    "        unpacked_list = [tuple(sublist) for sublist in packed_list]\n",
    "\n",
    "        # Create Polygon object for each lit of tuples\n",
    "        rows_list.append(Polygon(unpacked_list))\n",
    "\n",
    "    # Create new column and pass it the list\n",
    "    # of Polygon objects, one for each row\n",
    "    df['geometry'] = rows_list\n",
    "\n",
    "    # Create gdf from dataframe, pass in CRS\n",
    "    gdf = gpd.GeoDataFrame(df, crs='epsg:4326')\n",
    "\n",
    "    \"\"\"# Drop columns\n",
    "    try:\n",
    "        gdf.drop(columns=['bulkOrdered', 'ordered', 'summary', 'spatialFootprint.coordinates'],\n",
    "                 inplace=True)\n",
    "    except:\n",
    "        pass\"\"\"\n",
    "    try:\n",
    "        # Get list of fields to convert to datetime object\n",
    "        date_fields = ['acquisitionDate', \"startTime\", \"endTime\"]\n",
    "\n",
    "        # For each date field, convert to datetime format\n",
    "        for date_field in date_fields:\n",
    "            gdf[date_field] = pd.to_datetime(gdf[date_field], \n",
    "                                             infer_datetime_format=True)\n",
    "\n",
    "        #pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "        return gdf\n",
    "    \n",
    "    except KeyError:\n",
    "        \n",
    "        print(\"Unable to parse date fields\")\n",
    "        \n",
    "        return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderProducts(dataset_name, gdf):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a dataset name and geodataframe, adds gdf items to basket\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name: string\n",
    "    \n",
    "    gdf: geodataframe\n",
    "        Containing scenes of interest\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    (none)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert entity id column to list\n",
    "    entity_id_list = gdf.entityId.tolist()\n",
    "    \n",
    "    # Set up payload\n",
    "    op_payload = {\"datasetName\": dataset_name,\n",
    "                  \"apiKey\": api_key,\n",
    "                  \"entityIds\": entity_id_list}\n",
    "    \n",
    "    # Get JSON of available products; opr = order_products_response\n",
    "    opr = api_call(\"getorderproducts\", op_payload)\n",
    "\n",
    "    # Create empty dict to hold 'productId': 'productCode'\n",
    "    order_dict = {}\n",
    "\n",
    "    # Loop thru json\n",
    "    for entity in range(0, len(opr['data'])):\n",
    "\n",
    "        # Extract entityId\n",
    "        entity_id = opr['data'][entity].get('entityId')\n",
    "\n",
    "        # Extract product code\n",
    "        product_code = opr['data'][0].get('availableProducts')[\n",
    "            0].get('productCode')\n",
    "\n",
    "        order_dict[entity_id] = product_code\n",
    "\n",
    "    updateOrderScene(dataset_name, order_dict)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateOrderScene(dataset_name, order_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Adds order scene to basket by getting entityId from a dict\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name: string\n",
    "    \n",
    "    order_dict: dictionary\n",
    "        Of format{entityId: productCode}\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    none\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for entity_id, product_code in order_dict.items():\n",
    "\n",
    "        order_scene_payload = {\"apiKey\": api_key,\n",
    "                               \"datasetName\": dataset_name,\n",
    "                               \"entityId\": entity_id,\n",
    "                               \"productCode\": product_code,\n",
    "                               \"option\": \"None\",\n",
    "                               \"outputMedia\": \"DWNLD\"}\n",
    "\n",
    "        api_call(\"updateorderscene\",\n",
    "                 order_scene_payload)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitOrder():\n",
    "    \n",
    "    \"\"\"Submits current item basket\n",
    "    \n",
    "    Parameters\n",
    "    ------\n",
    "    none\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    order_resp: JSON\n",
    "        Returned after order placed\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    order_payload = {\"apiKey\": api_key}\n",
    "\n",
    "    # Allow user to cancel\n",
    "    ready = str(input(\"Ready to submit basket? (Y/N)\"))\n",
    "    \n",
    "    # Sure, why not\n",
    "    if ready.lower() in ('y', 'yes', 'ok', '1').:\n",
    "\n",
    "        order_resp = api_call(\"submitorder\", order_payload)\n",
    "\n",
    "        return order_resp\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(\"Order cancelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetSearch(dataset_name=None,\n",
    "                  start_date=None, end_date=None,\n",
    "                  latitude=None, longitude=None):\n",
    "    \"\"\"Searches all available datasets\"\"\"\n",
    "    dataset_search_payload = {\"apiKey\": api_key}\n",
    "\n",
    "    if dataset_name:\n",
    "        dataset_search_payload[\"datasetName\"] = dataset_name\n",
    "\n",
    "    if latitude and longitude:\n",
    "        dataset_search_payload['spatialFilter'] = {\"filterType\": \"mbr\",\n",
    "                                                   \"lowerLeft\": {\"latitude\": latitude,\n",
    "                                                                 \"longitude\": longitude},\n",
    "                                                   \"upperRight\": {\"latitude\": latitude,\n",
    "                                                                  \"longitude\": longitude}\n",
    "                                                   }\n",
    "\n",
    "    if start_date and end_date:\n",
    "        dataset_search_payload['temporalFilter'] = {\"startDate\": start_date,\n",
    "                                                    \"endDate\": end_date}\n",
    "\n",
    "    ds_search_response = api_call(\"datasets\", dataset_search_payload)\n",
    "\n",
    "    return ds_search_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
